apply plugin: 'java'
apply plugin: 'maven'

group = 'org.apdplat'
version = '1.1'

description = 'word分词是一个Java实现的中文分词组件，提供了多种基于词典的分词算法，并利用ngram模型来消除歧义。能准确识别英文、数字，以及日期、时间等数量词，能识别人名、地名、组织机构名等未登录词。同时提供了Lucene、Solr、ElasticSearch插件。'

sourceCompatibility = 1.8
targetCompatibility = 1.8

repositories {
    mavenCentral()        
}

dependencies {
    testCompile (
	'junit:junit:4.11',
    	'org.hamcrest:hamcrest-library:1.3',
    	'org.apache.lucene:lucene-test-framework:4.9.0',
    	'org.apache.lucene:lucene-queryparser:4.9.0',
    	'org.elasticsearch:elasticsearch:1.2.1:tests',
    	'com.carrotsearch.randomizedtesting:randomizedtesting-runner:2.1.3'
    )

    compile (
	'org.slf4j:slf4j-api:1.6.4',
    	'org.apache.lucene:lucene-core:4.9.0',
    	'org.apache.lucene:lucene-analyzers-common:4.9.0',
    	'org.elasticsearch:elasticsearch:1.2.1',
    	'redis.clients:jedis:2.5.1'
    )

    runtime ('ch.qos.logback:logback-classic:0.9.28') {
	exclude group: 'commons-logging', module: 'commons-logging'
    }
}

jar {
    exclude('**/org/apdplat/word/corpus/Corpus*')
    exclude('**/corpus/corpora.zip')
    exclude('**/corpus')
    exclude('**/logback.xml')
}

task wordDemo(type: JavaExec) {
       dependsOn classes
       description = 'Run org.apdplat.word.WordSegmenter'
       // Java main class to execute.
       main = 'org.apdplat.word.WordSegmenter'
       // We need to set the classpath.
       classpath sourceSets.main.runtimeClasspath
       // Extra options can be set.
       maxHeapSize = '1200m'
       jvmArgs '-client'
       // We can pass arguments to the main() method
       // of org.apdplat.word.WordSegmenter.
       args 'demo'
}
